# https://circleci.com/docs/2.0/

# We use version 2.1 of CircleCI's configuration format (the docs are still at
# the 2.0 link) in order to have access to Windows executors. This means we
# can't use dots in job names anymore. They have a new "parameters" feature
# that is supposed to remove the need to have version numbers in job names (the
# source of our dots), but switching to that is going to be a bigger refactor:
#
#   https://discuss.circleci.com/t/v2-1-job-name-validation/31123
#   https://circleci.com/docs/2.0/reusing-config/
#
version: 2.1

# Every job that pushes a Docker image from Docker Hub must authenticate to
# it.  Define a couple yaml anchors that can be used to supply the necessary
# credentials.

# First is a CircleCI job context which makes Docker Hub credentials available
# in the environment.
#
# Contexts are managed in the CircleCI web interface:
#
#  https://app.circleci.com/settings/organization/github/tahoe-lafs/contexts
dockerhub-context-template: &DOCKERHUB_CONTEXT
  context: "dockerhub-auth"

# Required environment for using the coveralls tool to upload partial coverage
# reports and then finish the process.
coveralls-environment: &COVERALLS_ENVIRONMENT
  COVERALLS_REPO_TOKEN: "JPf16rLB7T2yjgATIxFzTsEgMdN1UNq6o"

# Next is a Docker executor template that gets the credentials from the
# environment and supplies them to the executor.
dockerhub-auth-template: &DOCKERHUB_AUTH
  - auth:
      username: $DOCKERHUB_USERNAME
      password: $DOCKERHUB_PASSWORD

  # A template that can be shared between the two different image-building
# workflows.
.images: &IMAGES
  jobs:
    - "build-image-debian-11":
        <<: *DOCKERHUB_CONTEXT
    - "build-image-ubuntu-20-04":
        <<: *DOCKERHUB_CONTEXT
    - "build-image-ubuntu-22-04":
        <<: *DOCKERHUB_CONTEXT
    - "build-image-fedora-35":
        <<: *DOCKERHUB_CONTEXT
    - "build-image-oraclelinux-8":
        <<: *DOCKERHUB_CONTEXT
    # Restore later as PyPy38
    #- "build-image-pypy27-buster":
    #    <<: *DOCKERHUB_CONTEXT

parameters:
  # Control whether the image-building workflow runs as part of this pipeline.
  # Generally we do not want this to run because we don't need our
  # dependencies to move around all the time and because building the image
  # takes a couple minutes.
  #
  # An easy way to trigger a pipeline with this set to true is with the
  # rebuild-images.sh tool in this directory.  You can also do so via the
  # CircleCI web UI.
  build-images:
    default: false
    type: "boolean"

  # Control whether the test-running workflow runs as part of this pipeline.
  # Generally we do want this to run because running the tests is the primary
  # purpose of this pipeline.
  run-tests:
    default: true
    type: "boolean"

workflows:
  ci:
    when: "<< pipeline.parameters.run-tests >>"
    jobs:

  images:
    <<: *IMAGES

    # Build as part of the workflow but only if requested.
    when: "<< pipeline.parameters.build-images >>"

jobs:
  finish-coverage-report:
    docker:
      - <<: *DOCKERHUB_AUTH
        image: "python:3-slim"

    steps:
      - run:
          name: "Indicate completion to coveralls.io"
          environment:
            <<: *COVERALLS_ENVIRONMENT
          command: |
            pip install coveralls==3.3.1
            python -m coveralls --finish

  windows-server-2022:
    parameters:
      pythonVersion:
        description: >-
          An argument to pass to the `py` launcher to choose a Python version.
        type: "string"
        default: ""

    executor: "windows"
    environment:
      # Tweak Hypothesis to make its behavior more suitable for the CI
      # environment.  This should improve reproducibility and lessen the
      # effects of variable compute resources.
      TAHOE_LAFS_HYPOTHESIS_PROFILE: "ci"

      # Tell pip where its download cache lives.  This must agree with the
      # "save_cache" step below or caching won't really work right.
      PIP_CACHE_DIR: "pip-cache"

      # And tell pip where it can find out cached wheelhouse for fast wheel
      # installation, even for projects that don't distribute wheels.  This
      # must also agree with the "save_cache" step below.
      PIP_FIND_LINKS: "wheelhouse"

    steps:
      - "checkout"

      # If possible, restore a pip download cache to save us from having to
      # download all our Python dependencies from PyPI.
      - "restore_cache":
          keys:
            # The download cache and/or the wheelhouse may contain Python
            # version-specific binary packages so include the Python version
            # in this key, as well as the canonical source of our
            # dependencies.
            - &CACHE_KEY "pip-packages-v1-<< parameters.pythonVersion >>-{{ checksum \"setup.py\" }}"

      - "run":
          name: "Fix $env:PATH"
          command: |
            # The Python this job is parameterized is not necessarily the one
            # at the front of $env:PATH.  Modify $env:PATH so that it is so we
            # can just say "python" in the rest of the steps.  Also get the
            # related Scripts directory so tools from packages we install are
            # also available.
            $p = py -<<parameters.pythonVersion>> -c "import sys; print(sys.prefix)"
            $q = py -<<parameters.pythonVersion>> -c "import sysconfig; print(sysconfig.get_path('scripts'))"

            New-Item $Profile.CurrentUserAllHosts -Force
            # $p gets "python" on PATH and $q gets tools from packages we
            # install.  Note we carefully construct the string so that
            # $env:PATH is not substituted now but $p and $q are.  ` is the
            # PowerShell string escape character.
            Add-Content -Path $Profile.CurrentUserAllHosts -Value "`$env:PATH = `"$p;$q;`$env:PATH`""

      - "run":
          # It's faster to install a wheel than a source package.  If we don't
          # have a cached wheelhouse then build all of the wheels and dump
          # them into a directory where they can become a cached wheelhouse.
          # We would have built these wheels during installation anyway so it
          # doesn't cost us anything extra and saves us effort next time.
          name: "(Maybe) Build Wheels"
          command: |
              python -m pip install wheel setuptools
              python setup.py update_version # Cheat so we win the race to write the version string into _version.py
              python -m pip wheel --wheel-dir $env:PIP_FIND_LINKS .[testenv] .[test]

      - "save_cache":
          paths:
            # Make sure this agrees with PIP_CACHE_DIR in the environment.
            - "pip-cache"
            - "wheelhouse"
          key: *CACHE_KEY

      - "run":
          name: "Install Dependencies"
          environment:
            # By this point we should no longer need an index.
            PIP_NO_INDEX: "1"
          command: |
            python -m pip install .[testenv] .[test]

      - "run":
          name: "Display tool versions"
          command: |
            python misc/build_helpers/show-tool-versions.py

      - "run":
          name: "Run Unit Tests"
          environment:
            # Configure the results location for the subunitv2-file reporter
            # from subunitreporter
            SUBUNITREPORTER_OUTPUT_PATH: "test-results.subunit2"

            # Try to get prompt output from the reporter to avoid no-output
            # timeouts.
            PYTHONUNBUFFERED: "1"

          command: |
            # Run the test suite under coverage measurement using the
            # parameterized version of Python, writing subunitv2-format
            # results to the file given in the environment.
            python -b -m coverage run -m twisted.trial --reporter=subunitv2-file --rterrors allmydata

      - "run":
          name: "Upload Coverage"
          environment:
            <<: *COVERALLS_ENVIRONMENT
            # Mark the data as just one piece of many because we have more
            # than one instance of this job (two on Windows now, some on other
            # platforms later) which collects and reports coverage.  This is
            # necessary to cause Coveralls to merge multiple coverage results
            # into a single report.  Note the merge only happens when we
            # "finish" a particular build, as identified by its "build_num"
            # (aka "service_number").
            COVERALLS_PARALLEL: "true"
          command: |
            python -m pip install coveralls==3.3.1

            # .coveragerc sets parallel = True so we don't have a `.coverage`
            # file but a `.coverage.<unique stuff>` file (or maybe more than
            # one, but probably not).  coveralls can't work with these so
            # merge them before invoking it.
            python -m coverage combine

            # Now coveralls will be able to find the data, so have it do the
            # upload.  Also, have it strip the system config-specific prefix
            # from all of the source paths.
            $prefix = python -c "import sysconfig; print(sysconfig.get_path('purelib'))"
            python -m coveralls --basedir $prefix

      - "run":
          name: "Convert Result Log"
          command: |
            # subunit2junitxml exits with error if the result stream it is
            # converting has test failures in it!  So this step might fail.
            # Since the step in which we actually _ran_ the tests won't fail
            # even if there are test failures, this is a good thing for now.
            subunit2junitxml.exe --output-to=test-results.xml test-results.subunit2

      - "store_test_results":
          path: "test-results.xml"

      - "store_artifacts":
          path: "_trial_temp/test.log"

      - "store_artifacts":
          path: "eliot.log"

      - "store_artifacts":
          path: ".coverage"


executors:
  windows:
    # Choose a Windows environment that closest matches our testing
    # requirements and goals.
    # https://circleci.com/developer/orbs/orb/circleci/windows#executors-server-2022
    machine:
      image: "windows-server-2022-gui:current"
      shell: "powershell.exe -ExecutionPolicy Bypass"
    resource_class: "windows.large"
